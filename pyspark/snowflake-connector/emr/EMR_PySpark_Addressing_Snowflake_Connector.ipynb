{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "522026a0",
   "metadata": {},
   "source": [
    "# Geo Addressing SDK Sample for EMR using PySpark\n",
    "\n",
    "This sample driver program demonstrates the execution of geocoding operation of Geo Addressing SDK in EMR cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b59b56c",
   "metadata": {},
   "source": [
    "### Configuring the Spark Session\n",
    "- Before running the below command, copy the Geo Addressing SDK distribution contents inside an HDFS directory.\n",
    "- Provide the HDFS path of sdk jar available in the 'pyspark/driver' directory of the Geo Addressing SDK distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041b67e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:04:31.888482Z",
     "iopub.status.busy": "2022-08-29T12:04:31.888258Z",
     "iopub.status.idle": "2022-08-29T12:04:31.909016Z",
     "shell.execute_reply": "2022-08-29T12:04:31.908354Z",
     "shell.execute_reply.started": "2022-08-29T12:04:31.888456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars\": \"/user/hadoop/addressing/sdk/software/pyspark/driver/spectrum-bigdata-addressing-sdk-spark2_2.12-your_version.jar, /user/hadoop/addressing/lib/spark-snowflake_2.12-2.10.1-spark_3.2.jar, /user/hadoop/addressing/lib/snowflake-jdbc-3.13.22.jar\",\n",
    "        \"spark.sql.legacy.allowUntypedScalaUDF\": true\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666a651",
   "metadata": {},
   "source": [
    "### Creating a Spark Session\n",
    "- A SparkSession with above configurations will be instantiated after Importing the required PySpark Libraries automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb67b1df-6c81-44f6-8677-d4217d5dae59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:04:31.916139Z",
     "iopub.status.busy": "2022-08-29T12:04:31.915943Z",
     "iopub.status.idle": "2022-08-29T12:05:00.303115Z",
     "shell.execute_reply": "2022-08-29T12:05:00.302239Z",
     "shell.execute_reply.started": "2022-08-29T12:04:31.916117Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e24108f1bc40e19d8579aaf6a6a562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1666251443800_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-95-154.ec2.internal:20888/proxy/application_1666251443800_0001/\" class=\"emr-proxy-link\" emr-resource=\"j-LPD7P7434IBD\n",
       "\" application-id=\"application_1666251443800_0001\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-94-173.ec2.internal:8042/node/containerlogs/container_1666251443800_0001_01_000001/livy\" >Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the required Libraries of PySpark.\n",
    "from pyspark.sql.functions import lit, col, udf, create_map\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e836fe",
   "metadata": {},
   "source": [
    "### Create the Input DataFrame for the table in Snowflake using Snowflake Connector for Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c08fab-be24-44dc-b195-142af589e51c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:05:00.578530Z",
     "iopub.status.busy": "2022-08-29T12:05:00.578256Z",
     "iopub.status.idle": "2022-08-29T12:05:07.893477Z",
     "shell.execute_reply": "2022-08-29T12:05:07.892527Z",
     "shell.execute_reply.started": "2022-08-29T12:05:00.578494Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f10ce46c7224522a7f82a659f0cd883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------+------------------------+\n",
      "|ID      |ADDRESS                                     |COUNTRY                 |\n",
      "+--------+--------------------------------------------+------------------------+\n",
      "|16616048|171 INDUSTRIAL WAY,BRISBANE,CA,94005        |UNITED STATES OF AMERICA|\n",
      "|16617770|147 N LIVERMORE AVE STE C,LIVERMORE,CA,94550|UNITED STATES OF AMERICA|\n",
      "|16478264|17 W 19TH ST,NEW YORK,NY,10011              |UNITED STATES OF AMERICA|\n",
      "|16478276|3940 SLUSARIC RD,NORTH TONAWANDA,NY,14120   |UNITED STATES OF AMERICA|\n",
      "|16553442|1341 CENTER DR UNIT B,MEDFORD,OR,97501      |UNITED STATES OF AMERICA|\n",
      "+--------+--------------------------------------------+------------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Reading the dataframe from the table in the Snowflake using Snowflake Connector for Spark.\n",
    "sfOptions = {\n",
    "  \"sfUrl\": \"YOUR_SNOWFLAKE_URL\",\n",
    "  \"sfUser\": \"USERNAME\",\n",
    "  \"sfPassword\": \"PASSWORD\",\n",
    "  \"sfDatabase\": \"DATABASE_NAME\",\n",
    "  \"sfSchema\": \"SCHEMA_NAME\",\n",
    "  \"sfWarehouse\": \"WAREHOUSE_NAME\",\n",
    "  \"usestagingtable\": \"off\",\n",
    "  \"query\": \"select ID, ADDRESS, COUNTRY from YOUR_TABLE limit 100\"\n",
    "}\n",
    "\n",
    "SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n",
    "\n",
    "inputTable = spark.read.format(SNOWFLAKE_SOURCE_NAME) \\\n",
    "  .options(**sfOptions) \\\n",
    "  .load()\n",
    "\n",
    "inputTable.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6aa845",
   "metadata": {},
   "source": [
    "### Configuring the Spark Context\n",
    "- SparkContext is accessible from SparkSession.\n",
    "- Provide the HDFS path of the Python SDK Zip file available in the 'pyspark/driver' directory of the Geo Addressing SDK distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13f8919-353b-498a-9756-ef71775fd7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:05:00.304881Z",
     "iopub.status.busy": "2022-08-29T12:05:00.304605Z",
     "iopub.status.idle": "2022-08-29T12:05:00.576655Z",
     "shell.execute_reply": "2022-08-29T12:05:00.575866Z",
     "shell.execute_reply.started": "2022-08-29T12:05:00.304846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b388bc7676a44737b67d4b8b6d2b51aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a Spark Context from Spark Session.\n",
    "sc = spark.sparkContext\n",
    "sc.addPyFile('hdfs:///user/hadoop/addressing/sdk/software/pyspark/driver/spectrum-bigdata-addressing-sdk-pyspark-your_version.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe2210",
   "metadata": {},
   "source": [
    "### Importing the required Geo Addressing SDK Python classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62be71b-0b8d-4cea-b878-93cbda24ee75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:05:07.895553Z",
     "iopub.status.busy": "2022-08-29T12:05:07.895159Z",
     "iopub.status.idle": "2022-08-29T12:05:07.967872Z",
     "shell.execute_reply": "2022-08-29T12:05:07.967253Z",
     "shell.execute_reply.started": "2022-08-29T12:05:07.895512Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998cc77fa9114ba7b787f4d8c41e2dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the required Geo Addressing SDK Python classes which are present in the above passed zip file.\n",
    "from addressing.DownloadManagerBuilder import DownloadManagerBuilder\n",
    "from addressing.AddressingBuilder import AddressingBuilder\n",
    "from addressing.HDFSDownloader import HDFSDownloader\n",
    "from addressing.S3Downloader import S3Downloader\n",
    "from addressing.LocalFilePassthroughDownloader import LocalFilePassthroughDownloader\n",
    "from addressing.PreferencesBuilder import PreferencesBuilder\n",
    "from addressing.HadoopConfiguration import HadoopConfiguration\n",
    "from addressing.UDFExecutor import UDFExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6be0ee",
   "metadata": {},
   "source": [
    "### Creating the PySpark Geocode UDF\n",
    "- For more information on configuring and creating the required UDF, please visit the documentation page: https://docs.precisely.com/docs/sftw/hadoop/landingpage/docs/geocoding/webhelp/Geocoding/source/geocoding/addressing/addressing_spark_api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7c830c-f4a4-4319-9661-30e3ab00b141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:07:44.413318Z",
     "iopub.status.busy": "2022-08-29T12:07:44.413076Z",
     "iopub.status.idle": "2022-08-29T12:07:44.677771Z",
     "shell.execute_reply": "2022-08-29T12:07:44.677061Z",
     "shell.execute_reply.started": "2022-08-29T12:07:44.413294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403331da3d994de091551f7db76b1e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuring the AddressingBuilder using Resource Location.\n",
    "addressingBuilder = AddressingBuilder() \\\n",
    ".withResourcesLocation(\"/mnt/pb/geocoding/software/resources/\")\n",
    "\n",
    "# Configuring the UDF Builder as per Required Preferences, Output Fields and Error Fields.\n",
    "udfBuilder = addressingBuilder.udfBuilder() \\\n",
    ".withPreferences(PreferencesBuilder().withReturnAllInfo(True).build()) \\\n",
    ".withOutputFields(\"address.formattedStreetAddress as formattedStreetAddress\",\n",
    "                                                   \"address.formattedLocationAddress as formattedLocationAddress\",\n",
    "                                                   \"location.feature.geometry.coordinates.x as x\",\n",
    "                                                   \"location.feature.geometry.coordinates.y as y\",\n",
    "                                                   \"customFields['PB_KEY'] as 'PB_KEY'\") \\\n",
    ".withErrorField(\"error\")\n",
    "\n",
    "\n",
    "# Creating the Geocode UDF.\n",
    "geocodeUDF = udfBuilder.forGeocode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ec8092-ea5f-4944-84da-697675ff2e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T12:07:44.679288Z",
     "iopub.status.busy": "2022-08-29T12:07:44.679033Z",
     "iopub.status.idle": "2022-08-29T12:07:53.990691Z",
     "shell.execute_reply": "2022-08-29T12:07:53.989979Z",
     "shell.execute_reply.started": "2022-08-29T12:07:44.679254Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071c92b1a7b347c09e32e1c47b0b29d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------+\n",
      "|GEOCODE_OUTPUT                                                                                    |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "|{171 INDUSTRIAL WAY, BRISBANE, CA  94005-1003, -122.406438, 37.698568, P00002T1CTL2, null}        |\n",
      "|{147 N LIVERMORE AVE STE C, LIVERMORE, CA  94550-3113, -121.770171, 37.683711, P00002T4TIZ5, null}|\n",
      "|{17 W 19TH ST, NEW YORK, NY  10011-4332, -73.992429, 40.739649, P0000GL13ZK3, null}               |\n",
      "|{3940 SLUSARIC RD, NORTH TONAWANDA, NY  14120-9558, -78.830092, 43.105778, P0000GL50UPY, null}    |\n",
      "|{1341 CENTER DR UNIT B, MEDFORD, OR  97501-7947, -122.85291, 42.312725, P0000IVQPBAF, null}       |\n",
      "+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Execute the Geocode UDF by passing the approprite fields from the Input Data.\n",
    "geocodeOutput = inputTable.withColumn(\"GEOCODE_OUTPUT\", UDFExecutor().apply(geocodeUDF,\n",
    "                                                                            create_map(lit(\"addressLines[0]\"), col(\"ADDRESS\"), \n",
    "                                                                                       lit(\"country\"), col(\"COUNTRY\"))) \\\n",
    "                                     ).persist()\n",
    "\n",
    "# Save the Geocode Output inside a HDFS directory\n",
    "geocodeOutput.select(\"*\", \"GEOCODE_OUTPUT.*\").drop(\"GEOCODE_OUTPUT\") \\\n",
    ".write.mode(\"overwrite\").options(**{\"header\":\"true\"}).format(\"csv\").save(\"/user/hadoop/addressing/output\")\n",
    "\n",
    "# Extract the required fields from the Geocoded Output\n",
    "geocodeOutput = geocodeOutput.withColumn(\"LAT\", geocodeOutput[\"GEOCODE_OUTPUT\"].x.cast(DoubleType()))\n",
    "geocodeOutput = geocodeOutput.withColumn(\"LON\", geocodeOutput[\"GEOCODE_OUTPUT\"].y.cast(DoubleType()))\n",
    "geocodeOutput = geocodeOutput.withColumn(\"PB_KEY\", geocodeOutput['GEOCODE_OUTPUT'].PB_KEY)\n",
    "geocodeOutput.select('GEOCODE_OUTPUT').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f75c9",
   "metadata": {},
   "source": [
    "### Displaying the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c383a3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaf01d0aa134017a24c54cbe151ba67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------+------------------------+-----------+---------+------------+\n",
      "|ID      |ADDRESS                                     |COUNTRY                 |LAT        |LON      |PB_KEY      |\n",
      "+--------+--------------------------------------------+------------------------+-----------+---------+------------+\n",
      "|16616048|171 INDUSTRIAL WAY,BRISBANE,CA,94005        |UNITED STATES OF AMERICA|-122.406438|37.698568|P00002T1CTL2|\n",
      "|16617770|147 N LIVERMORE AVE STE C,LIVERMORE,CA,94550|UNITED STATES OF AMERICA|-121.770171|37.683711|P00002T4TIZ5|\n",
      "|16478264|17 W 19TH ST,NEW YORK,NY,10011              |UNITED STATES OF AMERICA|-73.992429 |40.739649|P0000GL13ZK3|\n",
      "|16478276|3940 SLUSARIC RD,NORTH TONAWANDA,NY,14120   |UNITED STATES OF AMERICA|-78.830092 |43.105778|P0000GL50UPY|\n",
      "|16553442|1341 CENTER DR UNIT B,MEDFORD,OR,97501      |UNITED STATES OF AMERICA|-122.85291 |42.312725|P0000IVQPBAF|\n",
      "+--------+--------------------------------------------+------------------------+-----------+---------+------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Displaying the result of the Geocode operation. \n",
    "geocodeOutput.select('ID', 'ADDRESS', 'COUNTRY', 'LAT', 'LON', 'PB_KEY').show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
