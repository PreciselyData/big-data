{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b31a0920-6ebd-4ad7-963b-fe03b1db56aa","showTitle":false,"title":""}},"source":["# Spectrum Spatial Addressing for Databricks - Installation\n","This is a sample installation file having information about how to install all the required configurations related to OAS SDK."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"143f74e9-58b4-40c8-8292-51019b275240","showTitle":false,"title":""}},"source":["# Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cf8008ee-00f3-4506-8f4e-c7c109710dbf","showTitle":true,"title":"Configuration and Variables"}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Wrote 2657 bytes.\n","Out[6]: True</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Wrote 2657 bytes.\nOut[6]: True</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Alter the following SDK_URL to point to the location where you placed the spectrum-bigdata-addressing-VERSION.zip. See the README for links to the documentation covering how to create presigned URL's for AWS and Azure.\n","\n","import datetime\n","\n","# Update the following with the API and Secret keys for your DataExperience account; these can be generated by visiting https://data.precisely.com/autodownload.\n","PB_API_KEY = \"YOUR_API_KEY\"\n","PB_SECRET = \"YOUR_API_SECRET\"\n","\n","# SDK Download URL\n","SDK_URL = \"YOUR_PRESIGNED_AWS_S3_URL_OR_DBFS_ZIP_PATH\"\n","\n","# We will be installing to the following directory. You can change the directory to suit your environment - you will need to use the same value in the Geocoding Demo Workspace.\n","AddressingRootDBFS = \"/addressing\"\n","\n","# This is the version of the latest vintage whenever updated to current. The required format is \"(YEAR.MONTH)\".\n","DATA_VINTAGE = \"2022.3\"\n","\n","# This is the release date of the latest vintage by default \"year-month-first date of the month\". For example, 2019-12-01.\n","DATA_RELEASE_DATE =\"2022-03-20\"\n","\n","# Configure the datasets to be downloaded from data.precisely.com.\n","SDM_GEOCODING_SPDS = [f\"Geocoding MLD US#United States#All USA#Spectrum Platform Data#1.0.0#{DATA_VINTAGE}#{DATA_RELEASE_DATE}\",\n","                      f\"Geocoding TT Street US#United States#All USA#Spectrum Platform Data#1.0.0#{DATA_VINTAGE}#{DATA_RELEASE_DATE}\"]\n","\n","today = datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S')\n","\n","\n","# Local Environment Setup - The remaining lines should not need to be modified\n","DBFS_BASE_LOCATION = f\"{AddressingRootDBFS}\"\n","DBFS_SDK_EXTRACT_LOCATION = f\"{DBFS_BASE_LOCATION}/sdk\"\n","DBFS_SDK_LOCATION = f\"{DBFS_SDK_EXTRACT_LOCATION}/spectrum-bigdata-addressing*\"\n","DBFS_DATA_LOCATION = f\"{DBFS_BASE_LOCATION}/data\"\n","\n","LOCAL_DATA_TMP = f\"{DBFS_BASE_LOCATION}/tmp/data\"\n","LOCAL_DATA_ZIPPED = f\"{LOCAL_DATA_TMP}/zip\"\n","LOCAL_DATA_UNZIPPED = f\"{LOCAL_DATA_TMP}/unzipped\"\n","\n","# Add the pdx sdk jar from github to your Filestore.\n","PDX_SDK_URL = \"https://raw.githubusercontent.com/PreciselyData/big-data/dev/databricks-geocoding/lib/precisely-bigdata-pdx-sdk3.0.1-full.jar\"\n","\n","PDX_CLASSNAME = \"com.precisely.pdx.sdkexample.SampleDemoApp\"\n","DBFS_PDX_SDK_JAR = f\"{DBFS_SDK_EXTRACT_LOCATION}/pdx-sdk.jar\"\n","\n","# We did this in any %sh command to ensure variables are available in the environment.\n","dbutils.fs.put(\"file:///dbricks_env.sh\", f\"\"\"#!/bin/bash\n","\n","export SDK_URL=\"{SDK_URL}\"\n","export PDX_API_KEY={PB_API_KEY}\n","export PDX_SECRET={PB_SECRET}\n","export DATA_VINTAGE={DATA_VINTAGE}\n","export DATA_RELEASE_DATE={DATA_RELEASE_DATE}\n","export DBFS_SDK_EXTRACT_LOCATION=/dbfs{DBFS_SDK_EXTRACT_LOCATION}\n","export DBFS_SDK_LOCATION=/dbfs{DBFS_SDK_LOCATION}\n","export DBFS_DATA_LOCATION=/dbfs{DBFS_DATA_LOCATION}\n","export LOCAL_DATA_TMP={LOCAL_DATA_TMP}\n","export LOCAL_DATA_ZIPPED={LOCAL_DATA_ZIPPED}\n","export LOCAL_DATA_UNZIPPED={LOCAL_DATA_UNZIPPED}\n","export PDX_SDK_URL={PDX_SDK_URL}\n","export PDX_CLASSNAME={PDX_CLASSNAME}\n","export DBFS_PDX_SDK_JAR=/dbfs{DBFS_PDX_SDK_JAR}\n","export GEOCODING_SPDS={\"({})\".format(\" \".join(list(map(lambda x: '\"{}\"'.format(x), SDM_GEOCODING_SPDS))))}\n","\n","\"\"\", True)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"bbb36782-ce75-4282-b871-fbf0e8246d5d","showTitle":true,"title":"Install SDK to DBFS"}},"outputs":[],"source":["%sh . /dbricks_env.sh\n","\n","rm -rf $DBFS_SDK_EXTRACT_LOCATION\n","mkdir -p $DBFS_SDK_EXTRACT_LOCATION\n","\n","if [ ! -z \"$SDK_URL\" ]\n","then\n","  echo \"Installing addressing SDK...\"\n","  curl -o addressing-sdk.zip \"$SDK_URL\"\n","  unzip -d $DBFS_SDK_EXTRACT_LOCATION addressing-sdk.zip\n","else\n","  echo \"Not installing addressing SDK\"\n","fi"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"bf1590f1-425d-4e59-a660-42cb663959dd","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">Installing PDX SDK...\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 5578k  100 5578k    0     0  24.2M      0 --:--:-- --:--:-- --:--:-- 24.2M\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">Installing PDX SDK...\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 5578k  100 5578k    0     0  24.2M      0 --:--:-- --:--:-- --:--:-- 24.2M\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["%sh . /dbricks_env.sh\n","\n","if [ ! -z \"$PDX_SDK_URL\" ]\n","then\n","  echo \"Installing PDX SDK...\"\n","  curl -o $DBFS_PDX_SDK_JAR \"$PDX_SDK_URL\"\n","else\n","  echo \"Not installing geocoding SDK\"\n","fi"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d1a7e3c8-ced4-48ab-a47f-916581ccb482","showTitle":false,"title":""}},"source":["## Install Data"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0682d1f7-24bd-4e8b-bf1e-26614022fdd2","showTitle":true,"title":"Download Geocoding Reference Data"}},"outputs":[],"source":["%sh . /dbricks_env.sh\n","rm -rf $DBFS_DATA_LOCATION\n","mkdir -p $DBFS_DATA_LOCATION\n","printf '%s\\n' \"${GEOCODING_SPDS[@]}\" | xargs -P 4 -I {spd} java -cp $DBFS_PDX_SDK_JAR $PDX_CLASSNAME -a $PDX_API_KEY -s $PDX_SECRET -d $DBFS_DATA_LOCATION -dd \\\"{spd}\\\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ea88b25f-e67b-4405-aaeb-dafe0d57c74c","showTitle":true,"title":"Create Geocoding Library & Attach to Cluster"}},"outputs":[],"source":["%sh . /dbricks_env.sh\n","\n","echo \"If the SDK has been installed or updated, you should now create the Databricks library and attach it to your cluster.\"\n","echo \"\"\n","echo \"Choose the jar below to be uploaded in the cluster:\"\n","\n","ls $DBFS_SDK_LOCATION/pyspark/sdk/lib/spectrum-bigdata-addressing-sdk-spark*.jar | sed 's/\\/dbfs/dbfs:/'"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":4183357742416111,"dataframes":["_sqldf"]},"pythonIndentUnit":2},"notebookName":"Databricks_Addressing_Installation_DBFS_Temp","notebookOrigID":4183357742416103,"widgets":{}},"kernelspec":{"display_name":"Python 3.9.13 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13"},"vscode":{"interpreter":{"hash":"11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"}}},"nbformat":4,"nbformat_minor":0}
